{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "3        1        1      0            1             0                 1   \n",
       "4        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone      ...        \\\n",
       "0                  0         0         0            0      ...         \n",
       "1                  0         0         0            0      ...         \n",
       "2                  0         0         0            0      ...         \n",
       "3                  0         0         0            0      ...         \n",
       "4                  0         0         0            0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:////home/workspace/matheus_project.db')\n",
    "df = pd.read_sql(\"SELECT * FROM ETL_part\", engine)\n",
    "X = df[\"message\"]\n",
    "Y = df.drop(columns=[\"id\",\"original\",\"genre\",\"message\"])\n",
    "\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a comitee in delmas 19  rue   street   janvier  impasse charite  2  we have about 500 people in a temporary shelter and we are in dire need of water  food  medications  tents and clothes  please stop by and see us \n"
     ]
    }
   ],
   "source": [
    "# Normalize text\n",
    "\n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test part of tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'comitee', 'in', 'delmas', '19', 'rue', 'street', 'janvier', 'impasse', 'charite', '2', 'we', 'have', 'about', '500', 'people', 'in', 'a', 'temporary', 'shelter', 'and', 'we', 'are', 'in', 'dire', 'need', 'of', 'water', 'food', 'medications', 'tents', 'and', 'clothes', 'please', 'stop', 'by', 'and', 'see', 'us']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', 'DT'),\n",
       " ('comitee', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('delmas', 'NN'),\n",
       " ('19', 'CD'),\n",
       " ('rue', 'JJ'),\n",
       " ('street', 'NN'),\n",
       " ('janvier', 'NN'),\n",
       " ('impasse', 'VBZ'),\n",
       " ('charite', 'JJ'),\n",
       " ('2', 'CD'),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('about', 'IN'),\n",
       " ('500', 'CD'),\n",
       " ('people', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('temporary', 'JJ'),\n",
       " ('shelter', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('dire', 'JJ'),\n",
       " ('need', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('water', 'NN'),\n",
       " ('food', 'NN'),\n",
       " ('medications', 'NNS'),\n",
       " ('tents', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('clothes', 'NNS'),\n",
       " ('please', 'VBP'),\n",
       " ('stop', 'VB'),\n",
       " ('by', 'IN'),\n",
       " ('and', 'CC'),\n",
       " ('see', 'VB'),\n",
       " ('us', 'PRP')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import statements\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "token = word_tokenize(text)\n",
    "print(token)\n",
    "\n",
    "# tag each word with part of speech\n",
    "pos_tag(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "comitee\n",
      "in\n",
      "delmas\n",
      "19\n",
      "rue\n",
      "street\n",
      "janvier\n",
      "impasse\n",
      "charite\n",
      "2\n",
      "we\n",
      "have\n",
      "about\n",
      "500\n",
      "people\n",
      "in\n",
      "a\n",
      "temporary\n",
      "shelter\n",
      "and\n",
      "we\n",
      "are\n",
      "in\n",
      "dire\n",
      "need\n",
      "of\n",
      "water\n",
      "food\n",
      "medication\n",
      "tent\n",
      "and\n",
      "clothes\n",
      "please\n",
      "stop\n",
      "by\n",
      "and\n",
      "see\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "lemma = nltk.WordNetLemmatizer()\n",
    "for i in token:\n",
    "    print(lemma.lemmatize(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text =  re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    token = word_tokenize(text)\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    return [lemma.lemmatize(i).strip() for i in token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('cvt', CountVectorizer(tokenizer=tokenize)),\n",
    "                     ('tf', TfidfTransformer()),\n",
    "                     ('model', MultiOutputClassifier(RandomForestClassifier())),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cvt', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state = 42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pipeline.predict(X_test)\n",
    "prediction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: related \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.33      0.44      2054\n",
      "          1       0.81      0.94      0.87      6534\n",
      "          2       0.58      0.30      0.39        64\n",
      "\n",
      "avg / total       0.77      0.79      0.76      8652\n",
      "\n",
      "Column: request \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93      7180\n",
      "          1       0.83      0.38      0.52      1472\n",
      "\n",
      "avg / total       0.88      0.88      0.86      8652\n",
      "\n",
      "Column: offer \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8614\n",
      "          1       0.00      0.00      0.00        38\n",
      "\n",
      "avg / total       0.99      1.00      0.99      8652\n",
      "\n",
      "Column: aid_related \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.87      0.79      5107\n",
      "          1       0.74      0.53      0.62      3545\n",
      "\n",
      "avg / total       0.73      0.73      0.72      8652\n",
      "\n",
      "Column: medical_help \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      7951\n",
      "          1       0.61      0.10      0.17       701\n",
      "\n",
      "avg / total       0.90      0.92      0.89      8652\n",
      "\n",
      "Column: medical_products \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      8206\n",
      "          1       0.64      0.07      0.13       446\n",
      "\n",
      "avg / total       0.94      0.95      0.93      8652\n",
      "\n",
      "Column: search_and_rescue \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      8426\n",
      "          1       0.56      0.04      0.07       226\n",
      "\n",
      "avg / total       0.96      0.97      0.96      8652\n",
      "\n",
      "Column: security \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8492\n",
      "          1       0.25      0.01      0.01       160\n",
      "\n",
      "avg / total       0.97      0.98      0.97      8652\n",
      "\n",
      "Column: military \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      8385\n",
      "          1       0.58      0.05      0.10       267\n",
      "\n",
      "avg / total       0.96      0.97      0.96      8652\n",
      "\n",
      "Column: child_alone \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8652\n",
      "\n",
      "avg / total       1.00      1.00      1.00      8652\n",
      "\n",
      "Column: water \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      8109\n",
      "          1       0.86      0.21      0.34       543\n",
      "\n",
      "avg / total       0.94      0.95      0.93      8652\n",
      "\n",
      "Column: food \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      7687\n",
      "          1       0.84      0.37      0.51       965\n",
      "\n",
      "avg / total       0.92      0.92      0.91      8652\n",
      "\n",
      "Column: shelter \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      7877\n",
      "          1       0.83      0.31      0.45       775\n",
      "\n",
      "avg / total       0.93      0.93      0.92      8652\n",
      "\n",
      "Column: clothing \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      8525\n",
      "          1       0.65      0.10      0.18       127\n",
      "\n",
      "avg / total       0.98      0.99      0.98      8652\n",
      "\n",
      "Column: money \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8461\n",
      "          1       0.83      0.03      0.05       191\n",
      "\n",
      "avg / total       0.98      0.98      0.97      8652\n",
      "\n",
      "Column: missing_people \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      8548\n",
      "          1       0.00      0.00      0.00       104\n",
      "\n",
      "avg / total       0.98      0.99      0.98      8652\n",
      "\n",
      "Column: refugees \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      8359\n",
      "          1       0.54      0.04      0.08       293\n",
      "\n",
      "avg / total       0.95      0.97      0.95      8652\n",
      "\n",
      "Column: death \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      8246\n",
      "          1       0.78      0.07      0.13       406\n",
      "\n",
      "avg / total       0.95      0.96      0.94      8652\n",
      "\n",
      "Column: other_aid \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93      7513\n",
      "          1       0.57      0.03      0.05      1139\n",
      "\n",
      "avg / total       0.83      0.87      0.81      8652\n",
      "\n",
      "Column: infrastructure_related \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97      8084\n",
      "          1       0.60      0.01      0.01       568\n",
      "\n",
      "avg / total       0.91      0.93      0.90      8652\n",
      "\n",
      "Column: transport \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      8245\n",
      "          1       0.65      0.04      0.08       407\n",
      "\n",
      "avg / total       0.94      0.95      0.93      8652\n",
      "\n",
      "Column: buildings \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      8211\n",
      "          1       0.78      0.07      0.12       441\n",
      "\n",
      "avg / total       0.94      0.95      0.93      8652\n",
      "\n",
      "Column: electricity \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8467\n",
      "          1       0.64      0.04      0.07       185\n",
      "\n",
      "avg / total       0.97      0.98      0.97      8652\n",
      "\n",
      "Column: tools \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      8599\n",
      "          1       0.00      0.00      0.00        53\n",
      "\n",
      "avg / total       0.99      0.99      0.99      8652\n",
      "\n",
      "Column: hospitals \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      8567\n",
      "          1       0.00      0.00      0.00        85\n",
      "\n",
      "avg / total       0.98      0.99      0.99      8652\n",
      "\n",
      "Column: shops \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8618\n",
      "          1       0.00      0.00      0.00        34\n",
      "\n",
      "avg / total       0.99      1.00      0.99      8652\n",
      "\n",
      "Column: aid_centers \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      8537\n",
      "          1       0.00      0.00      0.00       115\n",
      "\n",
      "avg / total       0.97      0.99      0.98      8652\n",
      "\n",
      "Column: other_infrastructure \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      8269\n",
      "          1       0.50      0.00      0.01       383\n",
      "\n",
      "avg / total       0.94      0.96      0.93      8652\n",
      "\n",
      "Column: weather_related \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89      6262\n",
      "          1       0.81      0.52      0.63      2390\n",
      "\n",
      "avg / total       0.83      0.83      0.82      8652\n",
      "\n",
      "Column: floods \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      7959\n",
      "          1       0.85      0.36      0.51       693\n",
      "\n",
      "avg / total       0.94      0.94      0.93      8652\n",
      "\n",
      "Column: storm \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      7840\n",
      "          1       0.73      0.33      0.45       812\n",
      "\n",
      "avg / total       0.91      0.93      0.91      8652\n",
      "\n",
      "Column: fire \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      8562\n",
      "          1       0.50      0.03      0.06        90\n",
      "\n",
      "avg / total       0.98      0.99      0.99      8652\n",
      "\n",
      "Column: earthquake \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      7865\n",
      "          1       0.88      0.73      0.80       787\n",
      "\n",
      "avg / total       0.97      0.97      0.97      8652\n",
      "\n",
      "Column: cold \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8465\n",
      "          1       0.78      0.07      0.14       187\n",
      "\n",
      "avg / total       0.98      0.98      0.97      8652\n",
      "\n",
      "Column: other_weather \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      8200\n",
      "          1       0.67      0.02      0.03       452\n",
      "\n",
      "avg / total       0.93      0.95      0.92      8652\n",
      "\n",
      "Column: direct_report \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91      6958\n",
      "          1       0.78      0.28      0.41      1694\n",
      "\n",
      "avg / total       0.84      0.84      0.81      8652\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "enumareted = enumerate(y_test)\n",
    "for i, j in enumareted:\n",
    "    print('''Column: {} \n",
    "    {}'''.format(j,classification_report(y_test[j], prediction[:, i])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'cvt__min_df': [1, 3],\n",
    "              'tf__use_idf':[True, False],\n",
    "              'model__estimator__n_estimators':[15, 25], \n",
    "              'model__estimator__min_samples_split':[2, 5, 10]}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters, verbose = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True, score=0.2201537147736977, total=  48.3s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   56.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True, score=0.22117847993168233, total=  48.7s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True, score=0.223436966176973, total=  49.2s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False, score=0.2175918018787361, total=  48.2s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False, score=0.21690862510674638, total=  48.6s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False, score=0.21967885206696275, total=  49.5s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  5.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True, score=0.22493595217762596, total= 1.3min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  7.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True, score=0.22578992314261315, total= 1.3min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  8.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True, score=0.23009907755380937, total= 1.3min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 10.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False, score=0.21861656703672075, total= 1.3min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False, score=0.22801024765157984, total= 1.3min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False, score=0.2350529552442774, total= 1.3min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True, score=0.21315115286080275, total=  41.7s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True, score=0.2143467122117848, total=  41.5s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True, score=0.21557909121967886, total=  41.8s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False, score=0.217933390264731, total=  40.1s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False, score=0.21895815542271563, total=  40.5s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False, score=0.22377861291424667, total=  40.7s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True, score=0.2187873612297182, total= 1.1min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True, score=0.23279248505550812, total= 1.1min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True, score=0.2290741373419884, total= 1.1min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False, score=0.2187873612297182, total= 1.0min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False, score=0.22578992314261315, total= 1.0min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False, score=0.23351554492654594, total= 1.0min\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True, score=0.2165670367207515, total=  38.1s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True, score=0.21315115286080275, total=  38.7s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True, score=0.22770755039289375, total=  38.7s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False, score=0.21451750640478223, total=  37.5s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False, score=0.22186165670367208, total=  37.1s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False, score=0.2307823710283567, total=  37.3s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True, score=0.21810418445772844, total=  59.1s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True, score=0.22783945345858242, total=  58.7s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True, score=0.23044072429108303, total=  59.1s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False, score=0.21998292058070026, total=  56.7s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False, score=0.2281810418445773, total=  56.7s\n",
      "[CV] cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=1, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False, score=0.2360778954560984, total=  57.4s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True, score=0.23023057216054654, total=  42.7s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True, score=0.23842869342442358, total=  42.8s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=True, score=0.23009907755380937, total=  42.9s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False, score=0.21639624252775405, total=  41.5s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False, score=0.22544833475661827, total=  41.4s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=15, tf__use_idf=False, score=0.21984967543559958, total=  41.5s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True, score=0.23484201537147736, total= 1.1min\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True, score=0.24047822374039282, total= 1.1min\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=True, score=0.24820635462931329, total= 1.1min\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False, score=0.2322801024765158, total= 1.1min\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False, score=0.23842869342442358, total= 1.1min\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=2, model__estimator__n_estimators=25, tf__use_idf=False, score=0.24103177314656646, total= 1.1min\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True, score=0.23159692570452606, total=  38.6s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True, score=0.22801024765157984, total=  39.0s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=True, score=0.23061154765971986, total=  39.2s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False, score=0.22305721605465414, total=  37.1s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False, score=0.22083689154568745, total=  36.9s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=15, tf__use_idf=False, score=0.22770755039289375, total=  37.1s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True, score=0.23911187019641333, total=  59.7s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True, score=0.23450042698548249, total= 1.0min\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=True, score=0.23983600956610865, total=  59.9s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False, score=0.23296327924850554, total=  56.4s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False, score=0.22715627668659266, total=  56.4s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=5, model__estimator__n_estimators=25, tf__use_idf=False, score=0.24205671335838744, total=  56.8s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True, score=0.22220324508966696, total=  37.1s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True, score=0.22681468830059778, total=  37.4s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=True, score=0.2316364878715408, total=  37.1s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False, score=0.22527754056362084, total=  35.0s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False, score=0.22971818958155424, total=  34.9s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=15, tf__use_idf=False, score=0.23454048513836692, total=  35.2s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True, score=0.2336464560204953, total=  56.9s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True, score=0.23347566182749788, total=  56.9s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=True, score=0.24701059104885548, total=  56.5s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False, score=0.23245089666951324, total=  53.3s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False, score=0.23518360375747224, total=  53.1s\n",
      "[CV] cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False \n",
      "[CV]  cvt__min_df=3, model__estimator__min_samples_split=10, model__estimator__n_estimators=25, tf__use_idf=False, score=0.24086094977792963, total=  53.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 73.0min finished\n"
     ]
    }
   ],
   "source": [
    "tuned_model = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_improved = tuned_model.predict(X_test)\n",
    "prediction_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: related \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.30      0.42      2054\n",
      "          1       0.81      0.95      0.88      6534\n",
      "          2       0.50      0.39      0.44        64\n",
      "\n",
      "avg / total       0.78      0.80      0.77      8652\n",
      "\n",
      "Column: request \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94      7180\n",
      "          1       0.85      0.45      0.59      1472\n",
      "\n",
      "avg / total       0.89      0.89      0.88      8652\n",
      "\n",
      "Column: offer \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8614\n",
      "          1       0.00      0.00      0.00        38\n",
      "\n",
      "avg / total       0.99      1.00      0.99      8652\n",
      "\n",
      "Column: aid_related \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.85      0.81      5107\n",
      "          1       0.75      0.63      0.68      3545\n",
      "\n",
      "avg / total       0.76      0.76      0.76      8652\n",
      "\n",
      "Column: medical_help \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      7951\n",
      "          1       0.63      0.11      0.19       701\n",
      "\n",
      "avg / total       0.90      0.92      0.90      8652\n",
      "\n",
      "Column: medical_products \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      8206\n",
      "          1       0.76      0.11      0.19       446\n",
      "\n",
      "avg / total       0.94      0.95      0.93      8652\n",
      "\n",
      "Column: search_and_rescue \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8426\n",
      "          1       0.62      0.09      0.16       226\n",
      "\n",
      "avg / total       0.97      0.97      0.97      8652\n",
      "\n",
      "Column: security \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8492\n",
      "          1       0.20      0.01      0.01       160\n",
      "\n",
      "avg / total       0.97      0.98      0.97      8652\n",
      "\n",
      "Column: military \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      8385\n",
      "          1       0.48      0.09      0.16       267\n",
      "\n",
      "avg / total       0.96      0.97      0.96      8652\n",
      "\n",
      "Column: child_alone \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8652\n",
      "\n",
      "avg / total       1.00      1.00      1.00      8652\n",
      "\n",
      "Column: water \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      8109\n",
      "          1       0.83      0.31      0.46       543\n",
      "\n",
      "avg / total       0.95      0.95      0.94      8652\n",
      "\n",
      "Column: food \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      7687\n",
      "          1       0.84      0.47      0.60       965\n",
      "\n",
      "avg / total       0.93      0.93      0.92      8652\n",
      "\n",
      "Column: shelter \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97      7877\n",
      "          1       0.81      0.36      0.50       775\n",
      "\n",
      "avg / total       0.93      0.94      0.92      8652\n",
      "\n",
      "Column: clothing \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      8525\n",
      "          1       0.80      0.09      0.17       127\n",
      "\n",
      "avg / total       0.98      0.99      0.98      8652\n",
      "\n",
      "Column: money \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8461\n",
      "          1       0.75      0.05      0.09       191\n",
      "\n",
      "avg / total       0.97      0.98      0.97      8652\n",
      "\n",
      "Column: missing_people \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      8548\n",
      "          1       1.00      0.01      0.02       104\n",
      "\n",
      "avg / total       0.99      0.99      0.98      8652\n",
      "\n",
      "Column: refugees \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      8359\n",
      "          1       0.50      0.05      0.09       293\n",
      "\n",
      "avg / total       0.95      0.97      0.95      8652\n",
      "\n",
      "Column: death \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      8246\n",
      "          1       0.81      0.20      0.33       406\n",
      "\n",
      "avg / total       0.96      0.96      0.95      8652\n",
      "\n",
      "Column: other_aid \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93      7513\n",
      "          1       0.53      0.04      0.07      1139\n",
      "\n",
      "avg / total       0.83      0.87      0.82      8652\n",
      "\n",
      "Column: infrastructure_related \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97      8084\n",
      "          1       0.50      0.00      0.01       568\n",
      "\n",
      "avg / total       0.91      0.93      0.90      8652\n",
      "\n",
      "Column: transport \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      8245\n",
      "          1       0.56      0.07      0.13       407\n",
      "\n",
      "avg / total       0.94      0.95      0.94      8652\n",
      "\n",
      "Column: buildings \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      8211\n",
      "          1       0.76      0.08      0.14       441\n",
      "\n",
      "avg / total       0.94      0.95      0.93      8652\n",
      "\n",
      "Column: electricity \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8467\n",
      "          1       0.73      0.04      0.08       185\n",
      "\n",
      "avg / total       0.97      0.98      0.97      8652\n",
      "\n",
      "Column: tools \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      8599\n",
      "          1       0.00      0.00      0.00        53\n",
      "\n",
      "avg / total       0.99      0.99      0.99      8652\n",
      "\n",
      "Column: hospitals \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      8567\n",
      "          1       0.00      0.00      0.00        85\n",
      "\n",
      "avg / total       0.98      0.99      0.99      8652\n",
      "\n",
      "Column: shops \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8618\n",
      "          1       0.00      0.00      0.00        34\n",
      "\n",
      "avg / total       0.99      1.00      0.99      8652\n",
      "\n",
      "Column: aid_centers \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      8537\n",
      "          1       0.00      0.00      0.00       115\n",
      "\n",
      "avg / total       0.97      0.99      0.98      8652\n",
      "\n",
      "Column: other_infrastructure \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      8269\n",
      "          1       0.00      0.00      0.00       383\n",
      "\n",
      "avg / total       0.91      0.96      0.93      8652\n",
      "\n",
      "Column: weather_related \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92      6262\n",
      "          1       0.84      0.70      0.76      2390\n",
      "\n",
      "avg / total       0.88      0.88      0.88      8652\n",
      "\n",
      "Column: floods \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98      7959\n",
      "          1       0.88      0.51      0.64       693\n",
      "\n",
      "avg / total       0.95      0.96      0.95      8652\n",
      "\n",
      "Column: storm \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      7840\n",
      "          1       0.76      0.62      0.68       812\n",
      "\n",
      "avg / total       0.94      0.95      0.94      8652\n",
      "\n",
      "Column: fire \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      8562\n",
      "          1       0.80      0.04      0.08        90\n",
      "\n",
      "avg / total       0.99      0.99      0.99      8652\n",
      "\n",
      "Column: earthquake \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      7865\n",
      "          1       0.87      0.79      0.83       787\n",
      "\n",
      "avg / total       0.97      0.97      0.97      8652\n",
      "\n",
      "Column: cold \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      8465\n",
      "          1       0.63      0.18      0.28       187\n",
      "\n",
      "avg / total       0.97      0.98      0.97      8652\n",
      "\n",
      "Column: other_weather \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      8200\n",
      "          1       0.73      0.05      0.10       452\n",
      "\n",
      "avg / total       0.94      0.95      0.93      8652\n",
      "\n",
      "Column: direct_report \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92      6958\n",
      "          1       0.80      0.37      0.51      1694\n",
      "\n",
      "avg / total       0.85      0.86      0.84      8652\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "enumareted = enumerate(y_test)\n",
    "for i, j in enumareted:\n",
    "    print('''Column: {} \n",
    "    {}'''.format(j,classification_report(y_test[j], prediction_improved[:, i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_disaster','wb') as f:\n",
    "    pickle.dump(tuned_model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
